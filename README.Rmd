---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# prov

<!-- badges: start -->
[![R build status](https://github.com/cboettig/prov/workflows/R-CMD-check/badge.svg)](https://github.com/cboettig/prov/actions)
<!-- badges: end -->

The goal of `prov` is to easily generate provenance records for common workflows using [DCAT-2](https://www.w3.org/TR/vocab-dcat-2/) and [PROV-O](https://www.w3.org/TR/prov-o/) ontologies, using the JSON-LD serialization for semantic (RDF) data.   

## Installation

You can install the released version of `prov` from [CRAN](https://CRAN.R-project.org) with:

``` r
install.packages("prov")
```

And the development version from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("cboettig/prov")
```
## Quickstart


```{r example}
library(prov)
```

We'll use temporary files for illustration only (CRAN policy). 
Really you would have paths to all these files (or URI identifiers for them).

```{r}
input_data <- tempfile(fileext = ".csv")
output_data <- tempfile(fileext = ".csv")
code <- tempfile(fileext = ".R")
p <- tempfile(fileext = ".json")
```


Here's a minimal workflow that generates output data from input data:

```{r}
out <- lm(mpg ~ disp, data = mtcars)

write.csv(mtcars, input_data)
write.csv(out$coefficients, output_data)
```

Let's make a dummy `.R` script just for this example.  

```{r}
writeLines("out <- lm(mpg ~ disp, data = mtcars)", code)
```


We are now ready to stick the pieces together into a provenance record!

```{r}
write_prov(input_data, code, output_data, prov = p)
```


Let's take a look at the results:

```{r}
writeLines(readLines(p))
```

If we include a `title`, these will be grouped as  to group these into a Dataset.
We use `append=FALSE` to overwrite the previous record.

```{r}
write_prov(input_data, code, output_data, prov = p,
            title = "example dataset with provenance",  append= FALSE)
```            


```{r include=FALSE}
unlink(p)
```


## Reproducible workflows


A key feature of content-based provenance trace is that we can run this again and again:
If we use the same data and get the same result, all our objects have the same ID.  By
default, these repeated calls append results to the `prov` file, but the only new data
added indicates a new `Activity` running the code at a different time, but generating
the same result.  

```{r}
out <- lm(mpg ~ disp, data = mtcars)
write.csv(mtcars, input_data)
write.csv(out$coefficients, output_data)
write_prov(input_data, code, output_data, prov = p)


out <- lm(mpg ~ disp, data = mtcars)
write.csv(mtcars, input_data)
write.csv(out$coefficients, output_data)
write_prov(input_data, code, output_data, prov = p)

```


```{r}
writeLines(readLines(p))
```


## Schema.org compatibility

Schema Dot Org (`sdo`) `Dataset`, used in [Google Dataset Search](https://datasetsearch.research.google.com/), is based upon the DCAT `Dataset` concept, and many terms can [crosswalk](https://www.w3.org/TR/vocab-dcat-2/#dcat-sdo) directly between DCAT2 and http://schema.org namespaces.  `prov` allows conversion between DCAT2 and Schema.org representation using an alternative context.  We are not aware of a mapping for most PROV-O terms, but have based the mapping
around translating `prov:Activity` to `sdo:Action`, `prov:used` to `sdo:object`,
and `prov:generated` to `sdo:result`.

```{r}
to_sdo(p)
```






